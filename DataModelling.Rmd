---
output:
  pdf_document: default
  html_document: default
---
## Data Modelling - Baseline Models

Now that we've completed feature engineering and feature selection, the next steps involve model training, evaluation, and possibly hyperparameter tuning to optimize model performance.

### Next Steps

1. **Model Training:**
   - Train different machine learning models on the selected features to compare their performance.

2. **Model Evaluation:**
   - Evaluate the performance of the trained models using appropriate metrics (e.g., RMSE, MAE, R^2) on the test dataset.

3. **Hyperparameter Tuning:**
   - Optimize the hyperparameters of the best-performing model to further improve its accuracy.

4. **Model Interpretation and Analysis:**
   - Interpret the results and analyze the model's performance to draw meaningful conclusions.

### Step-by-Step Guide

#### Step 1: Train Different Models

We can start by training a few common regression models, such as Linear Regression, Random Forest, and Gradient Boosting.

#### Step 2: Evaluate the Models

Evaluate the performance of each model using metrics such as RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), and R^2 (Coefficient of Determination).

#### Step 3: Hyperparameter Tuning

Use techniques like Grid Search or Random Search to find the best hyperparameters for the best-performing model.

### Detailed Implementation

#### Load Necessary Libraries

```{r}
# Install and load necessary libraries
#install.packages("randomForest")
#install.packages("gbm")
#install.packages("caret")
#install.packages("e1071")

library(randomForest)
library(gbm)
library(caret)
library(e1071)
```

#### Prepare Data

Ensure the data is ready with selected important features and split into training and testing sets.

```{r}
# Selected top features based on importance scores
selected_features <- c("TARGET_energy_lag1", "hour", "TARGET_energy_rollmean_3", 
                       "TARGET_energy_rollsd_3", "T8", "Tdewpoint", 
                       "T8_RH8_interaction", "T6_RH6_interaction", 
                       "Press_mm_hg", "RH_9")

# Create training and testing datasets with selected features
trainData_top <- trainData[, c(selected_features, "TARGET_energy")]
testData_top <- testData[, c(selected_features, "TARGET_energy")]
```

#### Train and Evaluate Models

##### Linear Regression

```{r}
# Train Linear Regression model
lm_model <- lm(TARGET_energy ~ ., data = trainData_top)

# Predict on test data
lm_predictions <- predict(lm_model, newdata = testData_top)

# Evaluate Linear Regression model
lm_rmse <- RMSE(lm_predictions, testData_top$TARGET_energy)
lm_mae <- MAE(lm_predictions, testData_top$TARGET_energy)
lm_r2 <- R2(lm_predictions, testData_top$TARGET_energy)

cat("Linear Regression - RMSE:", lm_rmse, "MAE:", lm_mae, "R^2:", lm_r2, "\n")
```

##### Random Forest

```{r}
# Train Random Forest model
rf_model <- randomForest(TARGET_energy ~ ., data = trainData_top, ntree = 100)

# Predict on test data
rf_predictions <- predict(rf_model, newdata = testData_top)

# Evaluate Random Forest model
rf_rmse <- RMSE(rf_predictions, testData_top$TARGET_energy)
rf_mae <- MAE(rf_predictions, testData_top$TARGET_energy)
rf_r2 <- R2(rf_predictions, testData_top$TARGET_energy)

cat("Random Forest - RMSE:", rf_rmse, "MAE:", rf_mae, "R^2:", rf_r2, "\n")
```

##### Gradient Boosting

```{r}
# Train Gradient Boosting model
gbm_model <- gbm(TARGET_energy ~ ., data = trainData_top, distribution = "gaussian", n.trees = 100)

# Predict on test data
gbm_predictions <- predict(gbm_model, newdata = testData_top, n.trees = 100)

# Evaluate Gradient Boosting model
gbm_rmse <- RMSE(gbm_predictions, testData_top$TARGET_energy)
gbm_mae <- MAE(gbm_predictions, testData_top$TARGET_energy)
gbm_r2 <- R2(gbm_predictions, testData_top$TARGET_energy)

cat("Gradient Boosting - RMSE:", gbm_rmse, "MAE:", gbm_mae, "R^2:", gbm_r2, "\n")
```

#### Hyperparameter Tuning

If Random Forest or Gradient Boosting shows the best performance, we can perform hyperparameter tuning for these models.

##### Hyperparameter Tuning for Random Forest

I will Comment Out the Follwoing Code block because I have performed hyperparameter tuning and saved the model. Hence, in the following sections, I will run it again print out metrics. 

```{r}

# # Set up the control function for training
# control <- trainControl(method = "cv", number = 5)
# tunegrid <- expand.grid(.mtry = c(2, 3, 4, 5, 6, 7))
# 
# # Train the model using cross-validation
# set.seed(123)
# rf_tuned <- train(TARGET_energy ~ ., data = trainData_top, method = "rf", 
#                   trControl = control, tuneGrid = tunegrid)
# 
# # Print the best tuning parameter
# print(rf_tuned$bestTune)
# 
# # Predict on test data
# rf_tuned_predictions <- predict(rf_tuned, newdata = testData_top)
# 
# # Evaluate the tuned model
# rf_tuned_rmse <- RMSE(rf_tuned_predictions, testData_top$TARGET_energy)
# rf_tuned_mae <- MAE(rf_tuned_predictions, testData_top$TARGET_energy)
# rf_tuned_r2 <- R2(rf_tuned_predictions, testData_top$TARGET_energy)
# 
# cat("Tuned Random Forest - RMSE:", rf_tuned_rmse, "MAE:", rf_tuned_mae, "R^2:", rf_tuned_r2, "\n")
# Load the tuned Random Forest model

# Save the tuned Random Forest model
#saveRDS(rf_tuned, file = "Models/rf_tuned_model.rds")


rf_tuned <- readRDS(file = "Models/rf_tuned_model.rds")


# Predict on test data using loaded models
rf_tuned_predictions <- predict(rf_tuned, newdata = testData_top)

# Evaluate the loaded models
rf_tuned_rmse <- RMSE(rf_tuned_predictions, testData_top$TARGET_energy)
rf_tuned_mae <- MAE(rf_tuned_predictions, testData_top$TARGET_energy)
rf_tuned_r2 <- R2(rf_tuned_predictions, testData_top$TARGET_energy)
cat("Tuned Random Forest - RMSE:", rf_tuned_rmse, "MAE:", rf_tuned_mae, "R^2:", rf_tuned_r2, "\n")

```


##### Hyperparameter Tuning for Gradient Boosting

```{r}
# # Set up the grid for tuning
# gbmGrid <- expand.grid(interaction.depth = c(1, 3, 5),
#                        n.trees = (1:3)*50,
#                        shrinkage = c(0.01, 0.1),
#                        n.minobsinnode = 10)
# 
# # Train the model using cross-validation
# set.seed(123)
# gbm_tuned <- train(TARGET_energy ~ ., data = trainData_top, method = "gbm", 
#                    trControl = control, tuneGrid = gbmGrid, verbose = FALSE)
# 
# # Print the best tuning parameters
# print(gbm_tuned$bestTune)
# 
# # Predict on test data
# gbm_tuned_predictions <- predict(gbm_tuned, newdata = testData_top)
# 
# # Evaluate the tuned model
# gbm_tuned_rmse <- RMSE(gbm_tuned_predictions, testData_top$TARGET_energy)
# gbm_tuned_mae <- MAE(gbm_tuned_predictions, testData_top$TARGET_energy)
# gbm_tuned_r2 <- R2(gbm_tuned_predictions, testData_top$TARGET_energy)
# 
# cat("Tuned Gradient Boosting - RMSE:", gbm_tuned_rmse, "MAE:", gbm_tuned_mae, "R^2:", gbm_tuned_r2, "\n")

# Save the tuned Gradient Boosting model
saveRDS(gbm_tuned, file = "Models/gbm_tuned_model.rds")




# Load the tuned Gradient Boosting model
gbm_tuned <- readRDS(file = "Models/gbm_tuned_model.rds")

gbm_tuned_predictions <- predict(gbm_tuned, newdata = testData_top)


gbm_tuned_rmse <- RMSE(gbm_tuned_predictions, testData_top$TARGET_energy)
gbm_tuned_mae <- MAE(gbm_tuned_predictions, testData_top$TARGET_energy)
gbm_tuned_r2 <- R2(gbm_tuned_predictions, testData_top$TARGET_energy)
cat("Tuned Gradient Boosting - RMSE:", gbm_tuned_rmse, "MAE:", gbm_tuned_mae, "R^2:", gbm_tuned_r2, "\n")
```


=========================================================

## Data Modelling - Advanced Models

#### LSTM
```{r}
# Install and load necessary packages
install.packages("keras")
install.packages("tensorflow")
install.packages("zoo")
library(keras)
library(tensorflow)
library(dplyr)
library(zoo)

# Assuming data is your dataset and TARGET_energy is your target variable
# Ensure the 'date' column is in datetime format
data$date <- as.POSIXct(data$date, format="%Y-%m-%d %H:%M:%S")

# Feature Engineering: Adding lagged features and rolling statistics
data <- data %>%
  mutate(
    lag1 = lag(TARGET_energy, 1),
    lag2 = lag(TARGET_energy, 2),
    lag3 = lag(TARGET_energy, 3),
    rollmean3 = zoo::rollmean(TARGET_energy, 3, fill = NA),
    rollmean6 = zoo::rollmean(TARGET_energy, 6, fill = NA),
    rollmean12 = zoo::rollmean(TARGET_energy, 12, fill = NA)
  ) %>%
  na.omit()

# Normalize the data
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

inverse_normalize <- function(x, orig_data) {
  return (x * (max(orig_data) - min(orig_data)) + min(orig_data))
}

# Apply normalization
data_normalized <- data %>%
  mutate_at(vars(TARGET_energy, lag1, lag2, lag3, rollmean3, rollmean6, rollmean12), normalize)

# Prepare the time series data
ts_data <- ts(data_normalized$TARGET_energy, frequency = 24) # Assuming hourly data

# Split the data into training and testing sets
train_size <- floor(0.8 * nrow(data_normalized))
train_data <- data_normalized[1:train_size, ]
test_data <- data_normalized[(train_size + 1):nrow(data_normalized), ]

# Convert to matrix format for LSTM
x_train <- array(data = as.matrix(train_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(train_data), 1, 6))
y_train <- array(data = train_data$TARGET_energy, dim = c(nrow(train_data), 1))
x_test <- array(data = as.matrix(test_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(test_data), 1, 6))
y_test <- array(data = test_data$TARGET_energy, dim = c(nrow(test_data), 1))

# Define the LSTM model with hyperparameter tuning
model <- keras_model_sequential() %>%
  layer_lstm(units = 100, input_shape = c(1, 6), return_sequences = TRUE, dropout = 0.2, recurrent_dropout = 0.2) %>%
  layer_lstm(units = 100, return_sequences = FALSE, dropout = 0.2, recurrent_dropout = 0.2) %>%
  layer_dense(units = 1)

model %>% compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam(learning_rate = 0.001)
)

# Train the model with increased epochs and batch size
history <- model %>% fit(
  x_train, y_train,
  epochs = 100,
  batch_size = 32,
  validation_data = list(x_test, y_test),
  verbose = 2
)

# Save the trained model
model %>% save_model_hdf5("lstm_energy_model.h5")



```


```{r}
# Install and load necessary packages
install.packages("keras")
install.packages("tensorflow")
library(keras)
library(tensorflow)
library(dplyr)

# Load the trained model
model <- load_model_hdf5("lstm_energy_model.h5")

# Prepare the time series data
ts_data <- ts(data_normalized$TARGET_energy, frequency = 24) # Assuming hourly data

# Split the data into training and testing sets
train_size <- floor(0.8 * nrow(data_normalized))
train_data <- data_normalized[1:train_size, ]
test_data <- data_normalized[(train_size + 1):nrow(data_normalized), ]

# Convert to matrix format for LSTM
x_train <- array(data = as.matrix(train_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(train_data), 1, 6))
y_train <- array(data = train_data$TARGET_energy, dim = c(nrow(train_data), 1))
x_test <- array(data = as.matrix(test_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(test_data), 1, 6))
y_test <- array(data = test_data$TARGET_energy, dim = c(nrow(test_data), 1))

# Make predictions
train_predict <- model %>% predict(x_train)
test_predict <- model %>% predict(x_test)

# Inverse the normalization
train_predict <- inverse_normalize(train_predict, data$TARGET_energy)
test_predict <- inverse_normalize(test_predict, data$TARGET_energy)
train_actual <- inverse_normalize(y_train, data$TARGET_energy)
test_actual <- inverse_normalize(y_test, data$TARGET_energy)

# Evaluate the model
lstm_rmse <- sqrt(mean((test_predict - test_actual)^2))
lstm_mae <- mean(abs(test_predict - test_actual))
lstm_r2 <- 1 - sum((test_predict - test_actual)^2) / sum((test_actual - mean(test_actual))^2)

cat("LSTM - RMSE:", lstm_rmse, "MAE:", lstm_mae, "R^2:", lstm_r2, "\n")

```


```{r LSTM Hyperparameter tuning}
# # Install and load necessary packages
# install.packages("keras")
# install.packages("zoo")
# library(keras)
# library(dplyr)
# library(zoo)
# 
# # Assuming data is your dataset and TARGET_energy is your target variable
# # Ensure the 'date' column is in datetime format
# data$date <- as.POSIXct(data$date, format="%Y-%m-%d %H:%M:%S")
# 
# # Feature Engineering: Adding lagged features and rolling statistics
# data <- data %>%
#   mutate(
#     lag1 = lag(TARGET_energy, 1),
#     lag2 = lag(TARGET_energy, 2),
#     lag3 = lag(TARGET_energy, 3),
#     rollmean3 = zoo::rollmean(TARGET_energy, 3, fill = NA),
#     rollmean6 = zoo::rollmean(TARGET_energy, 6, fill = NA),
#     rollmean12 = zoo::rollmean(TARGET_energy, 12, fill = NA)
#   ) %>%
#   na.omit()
# 
# # Normalize the data
# normalize <- function(x) {
#   return ((x - min(x)) / (max(x) - min(x)))
# }
# 
# inverse_normalize <- function(x, orig_data) {
#   return (x * (max(orig_data) - min(orig_data)) + min(orig_data))
# }
# 
# # Apply normalization
# data_normalized <- data %>%
#   mutate_at(vars(TARGET_energy, lag1, lag2, lag3, rollmean3, rollmean6, rollmean12), normalize)
# 
# # Prepare the time series data
# ts_data <- ts(data_normalized$TARGET_energy, frequency = 24) # Assuming hourly data
# 
# # Split the data into training and testing sets
# train_size <- floor(0.8 * nrow(data_normalized))
# train_data <- data_normalized[1:train_size, ]
# test_data <- data_normalized[(train_size + 1):nrow(data_normalized), ]
# 
# # Convert to matrix format for LSTM
# x_train <- array(data = as.matrix(train_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(train_data), 1, 6))
# y_train <- array(data = train_data$TARGET_energy, dim = c(nrow(train_data), 1))
# x_test <- array(data = as.matrix(test_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(test_data), 1, 6))
# y_test <- array(data = test_data$TARGET_energy, dim = c(nrow(test_data), 1))
# 
# # Define the LSTM model with hyperparameter tuning
# model <- keras_model_sequential() %>%
#   layer_lstm(units = 100, input_shape = c(1, 6), return_sequences = TRUE, dropout = 0.2, recurrent_dropout = 0.2) %>%
#   layer_lstm(units = 100, return_sequences = FALSE, dropout = 0.2, recurrent_dropout = 0.2) %>%
#   layer_dense(units = 1)
# 
# model %>% compile(
#   loss = 'mean_squared_error',
#   optimizer = optimizer_adam(learning_rate = 0.001)
# )
# 
# # Train the model with increased epochs and batch size
# history <- model %>% fit(
#   x_train, y_train,
#   epochs = 100,
#   batch_size = 32,
#   validation_data = list(x_test, y_test),
#   verbose = 2
# )
# 
# # Save the trained model
# model %>% save_model_hdf5("Models/lstm_energy_model.h5")
# 
# # Load the trained model (for future use)
# model <- load_model_hdf5("Models/lstm_energy_model.h5")
# 
# # Reshape the data for prediction
# x_train_reshaped <- array(data = as.matrix(train_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(train_data), 1, 6))
# x_test_reshaped <- array(data = as.matrix(test_data %>% select(lag1, lag2, lag3, rollmean3, rollmean6, rollmean12)), dim = c(nrow(test_data), 1, 6))
# 
# # Make predictions
# train_predict <- model %>% predict(x_train_reshaped)
# test_predict <- model %>% predict(x_test_reshaped)
# 
# # Inverse the normalization
# train_predict <- inverse_normalize(train_predict, data$TARGET_energy)
# test_predict <- inverse_normalize(test_predict, data$TARGET_energy)
# train_actual <- inverse_normalize(y_train, data$TARGET_energy)
# test_actual <- inverse_normalize(y_test, data$TARGET_energy)
# 
# # Evaluate the model
# lstm_rmse <- sqrt(mean((test_predict - test_actual)^2))
# lstm_mae <- mean(abs(test_predict - test_actual))
# lstm_r2 <- 1 - sum((test_predict - test_actual)^2) / sum((test_actual - mean(test_actual))^2)
# 
# cat("LSTM - RMSE:", lstm_rmse, "MAE:", lstm_mae, "R^2:", lstm_r2, "\n")



```



```{r}
# Save the trained model
#model %>% save_model_hdf5("Models/lstm_energy_model.h5")

# Load the trained model (for future use)
model <- load_model_hdf5("Models/lstm_energy_model.h5")

# Reshape the data for prediction
x_train_reshaped <- array(data = x_train, dim = c(nrow(x_train), 1, 6))
x_test_reshaped <- array(data = x_test, dim = c(nrow(x_test), 1, 6))

# Make predictions
train_predict <- model %>% predict(x_train_reshaped)
test_predict <- model %>% predict(x_test_reshaped)

# Inverse the normalization
train_predict <- inverse_normalize(train_predict, data$TARGET_energy)
test_predict <- inverse_normalize(test_predict, data$TARGET_energy)
train_actual <- inverse_normalize(y_train, data$TARGET_energy)
test_actual <- inverse_normalize(y_test, data$TARGET_energy)

# Evaluate the model
lstm_rmse <- sqrt(mean((test_predict - test_actual)^2))
lstm_mae <- mean(abs(test_predict - test_actual))
lstm_r2 <- 1 - sum((test_predict - test_actual)^2) / sum((test_actual - mean(test_actual))^2)

cat("LSTM - RMSE:", lstm_rmse, "MAE:", lstm_mae, "R^2:", lstm_r2, "\n")

```
### Feature Engineering for Random Forest

#### Now, since out of all models we saw that random forest had the best performance. Thus, we seperately engineer features for that and tune it for the better performance. 


Let's prepare the data for the Random Forest model and conduct feature engineering to enhance its performance. Random Forests are generally less sensitive to feature scaling and can handle a mix of feature types effectively. However, creating meaningful features can still improve model performance.

Here's how we can prepare the data and perform feature engineering for a Random Forest model:

1. **Lagged Features**: These capture the previous values of the target variable.
2. **Rolling Statistics**: These provide smoothed versions of the target variable over different windows.



```{r Feature Engineering for Random Forest}
# Install and load necessary packages
install.packages("randomForest")
install.packages("zoo")
library(randomForest)
library(dplyr)
library(zoo)

# Assuming data is your dataset and TARGET_energy is your target variable
# Ensure the 'date' column is in datetime format
data$date <- as.POSIXct(data$date, format="%Y-%m-%d %H:%M:%S")

# Feature Engineering: Adding lagged features and rolling statistics
data <- data %>%
  mutate(
    lag1 = lag(TARGET_energy, 1),
    lag2 = lag(TARGET_energy, 2),
    lag3 = lag(TARGET_energy, 3),
    lag4 = lag(TARGET_energy, 4),
    lag5 = lag(TARGET_energy, 5),
    lag6 = lag(TARGET_energy, 6),
    rollmean3 = zoo::rollmean(TARGET_energy, 3, fill = NA),
    rollmean6 = zoo::rollmean(TARGET_energy, 6, fill = NA),
    rollmean12 = zoo::rollmean(TARGET_energy, 12, fill = NA),
    rollmean24 = zoo::rollmean(TARGET_energy, 24, fill = NA)
  ) %>%
  na.omit()

# Split the data into training and testing sets
set.seed(42)
train_size <- floor(0.8 * nrow(data))
train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]

# Define the feature matrix and target vector
x_train <- train_data %>% select(-date, -TARGET_energy)
y_train <- train_data$TARGET_energy
x_test <- test_data %>% select(-date, -TARGET_energy)
y_test <- test_data$TARGET_energy

# Train the Random Forest model
set.seed(42)
rf_model <- randomForest(x = x_train, y = y_train, ntree = 500, mtry = 3, importance = TRUE)

# Make predictions
train_predict <- predict(rf_model, x_train)
test_predict <- predict(rf_model, x_test)

# Evaluate the model
rf_rmse <- sqrt(mean((test_predict - y_test)^2))
rf_mae <- mean(abs(test_predict - y_test))
rf_r2 <- 1 - sum((test_predict - y_test)^2) / sum((y_test - mean(y_test))^2)

cat("Random Forest - RMSE:", rf_rmse, "MAE:", rf_mae, "R^2:", rf_r2, "\n")

# Feature Importance
importance(rf_model)
varImpPlot(rf_model)

```

```{r}
# Save the Random Forest model
#save(rf_model, file = "random_forest_model.RData")

# Load the Random Forest model (in a different code block or session)
load("Models/random_forest_model.RData")

# Predict using the loaded model
train_predict <- predict(rf_model, x_train)
test_predict <- predict(rf_model, x_test)

# Evaluate the loaded model
rf_rmse <- sqrt(mean((test_predict - y_test)^2))
rf_mae <- mean(abs(test_predict - y_test))
rf_r2 <- 1 - sum((test_predict - y_test)^2) / sum((y_test - mean(y_test))^2)

cat("Random Forest - RMSE:", rf_rmse, "MAE:", rf_mae, "R^2:", rf_r2, "\n")

```





```{r Hyperparameter Tuning For Random Forest}
library(randomForest)
library(dplyr)
library(zoo)
library(caret)

# Assuming data is your dataset and TARGET_energy is your target variable
# Ensure the 'date' column is in datetime format
data$date <- as.POSIXct(data$date, format="%Y-%m-%d %H:%M:%S")

# Feature Engineering: Adding lagged features and rolling statistics
data <- data %>%
  mutate(
    lag1 = lag(TARGET_energy, 1),
    lag2 = lag(TARGET_energy, 2),
    lag3 = lag(TARGET_energy, 3),
    lag4 = lag(TARGET_energy, 4),
    lag5 = lag(TARGET_energy, 5),
    lag6 = lag(TARGET_energy, 6),
    rollmean3 = zoo::rollmean(TARGET_energy, 3, fill = NA),
    rollmean6 = zoo::rollmean(TARGET_energy, 6, fill = NA),
    rollmean12 = zoo::rollmean(TARGET_energy, 12, fill = NA),
    rollmean24 = zoo::rollmean(TARGET_energy, 24, fill = NA)
  ) %>%
  na.omit()

# Split the data into training and testing sets
set.seed(42)
train_size <- floor(0.8 * nrow(data))
train_data <- data[1:train_size, ]
test_data <- data[(train_size + 1):nrow(data), ]

# Define the feature matrix and target vector
x_train <- train_data %>% select(-date, -TARGET_energy)
y_train <- train_data$TARGET_energy
x_test <- test_data %>% select(-date, -TARGET_energy)
y_test <- test_data$TARGET_energy

# Combine x_train and y_train for caret
train_df <- cbind(x_train, TARGET_energy = y_train)

# Define the hyperparameter grid
mtry_grid <- c(2, 3, 4, 5, 6)

# Use caret's expand.grid for compatibility
hyper_grid <- expand.grid(mtry = mtry_grid)

# Define control parameters for cross-validation
control <- trainControl(method = "cv", number = 5)

# Train the model using cross-validation
rf_tuned <- train(
  TARGET_energy ~ ., 
  data = train_df,
  method = "rf",
  metric = "RMSE",
  tuneGrid = hyper_grid,
  trControl = control,
  ntree = 500 # Use a fixed number of trees for tuning
)

# Print the best hyperparameters
print(rf_tuned$bestTune)

# Train the final model with the best hyperparameters
set.seed(42)
rf_final <- randomForest(
  x = x_train,
  y = y_train,
  ntree = 500, # Use a fixed number of trees
  mtry = rf_tuned$bestTune$mtry,
  nodesize = 5, # Set nodesize directly
  importance = TRUE
)

# Make predictions with the final model
train_predict <- predict(rf_final, x_train)
test_predict <- predict(rf_final, x_test)

# Evaluate the final model
rf_final_rmse <- sqrt(mean((test_predict - y_test)^2))
rf_final_mae <- mean(abs(test_predict - y_test))
rf_final_r2 <- 1 - sum((test_predict - y_test)^2) / sum((y_test - mean(y_test))^2)

cat("Random Forest Final - RMSE:", rf_final_rmse, "MAE:", rf_final_mae, "R^2:", rf_final_r2, "\n")

# Feature Importance
importance(rf_final)
varImpPlot(rf_final)
```

### Explanation:
1. **Hyperparameter Grid Definition:**
   - `ntree` is fixed at 500 for tuning purposes to focus on `mtry` and `nodesize`.
   - `hyper_grid` includes `mtry` and `nodesize`.

2. **Cross-Validation Setup:**
   - `trainControl(method = "cv", number = 5)` defines 5-fold cross-validation.

3. **Model Training with Cross-Validation:**
   - `train()` trains the model using the grid of hyperparameters and cross-validation.

4. **Final Model Training:**
   - Uses the best hyperparameters found during cross-validation to train the final Random Forest model.

5. **Model Evaluation:**
   - Makes predictions and evaluates the performance of the final model using RMSE, MAE, and R^2.

```{r}

# Convert feature importance to a data frame
importance_df <- as.data.frame(importance(rf_final))
importance_df$Feature <- rownames(importance_df)
importance_df <- importance_df[order(-importance_df$`%IncMSE`), ]

# Plot using ggplot2
library(ggplot2)
ggplot(importance_df, aes(x = reorder(Feature, `%IncMSE`), y = `%IncMSE`)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Feature Importance", x = "Features", y = "% Increase in MSE") +
  theme(axis.text.y = element_text(size = 10), plot.margin = margin(t = 1, r = 1, b = 1, l = 1, unit = "cm"))

ggsave("feature_importance_plot.png", width = 10, height = 20)

```

```{r}
# Save the final model to a file
#save(rf_final, file = "rf_final_model.RData")

# Load the saved model
load("Models/rf_final_model.RData")

# Make predictions with the final model
train_predict <- predict(rf_final, x_train)
test_predict <- predict(rf_final, x_test)

# Evaluate the final model
rf_final_rmse <- sqrt(mean((test_predict - y_test)^2))
rf_final_mae <- mean(abs(test_predict - y_test))
rf_final_r2 <- 1 - sum((test_predict - y_test)^2) / sum((y_test - mean(y_test))^2)

cat("Random Forest Final - RMSE:", rf_final_rmse, "MAE:", rf_final_mae, "R^2:", rf_final_r2, "\n")

# Visualize Feature Importance
importance_df <- data.frame(
  Feature = rownames(importance(rf_final)),
  `%IncMSE` = importance(rf_final)[, "%IncMSE"],
  IncNodePurity = importance(rf_final)[, "IncNodePurity"]
)

```



